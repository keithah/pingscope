---
phase: 01-foundation
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - Sources/PingMonitor/Services/ConnectionWrapper.swift
  - Sources/PingMonitor/Services/PingService.swift
autonomous: true

must_haves:
  truths:
    - "PingService can measure TCP connection latency using async/await"
    - "Connection timeout fires exactly at deadline (no false timeouts from race conditions)"
    - "Connections are cancelled immediately when timeout fires (no late responses processed)"
    - "Cancelled tasks immediately cancel underlying NWConnection"
  artifacts:
    - path: "Sources/PingMonitor/Services/ConnectionWrapper.swift"
      provides: "Async wrapper for NWConnection"
      contains: "withCheckedThrowingContinuation"
    - path: "Sources/PingMonitor/Services/PingService.swift"
      provides: "Actor-isolated ping service"
      contains: "actor PingService"
  key_links:
    - from: "PingService.swift"
      to: "ConnectionWrapper.swift"
      via: "async connection measurement"
      pattern: "connectAsync|measureConnection"
    - from: "ConnectionWrapper.swift"
      to: "NWConnection"
      via: "callback to async bridge"
      pattern: "NWConnection.*stateUpdateHandler"
    - from: "PingService.swift"
      to: "withThrowingTaskGroup"
      via: "timeout racing pattern"
      pattern: "withThrowingTaskGroup"
---

<objective>
Implement the core ping measurement with proper async/await patterns and timeout handling.

Purpose: This is the heart of Phase 1 - the async connection wrapper and actor-isolated PingService that eliminate the race conditions from the previous implementation. The timeout racing pattern ensures immediate failure when deadline passes, and withTaskCancellationHandler ensures connections are cleaned up on cancellation.

Output: Working PingService actor that can measure TCP/UDP latency with accurate timeouts.
</objective>

<execution_context>
@/Users/keith/.claude/get-shit-done/workflows/execute-plan.md
@/Users/keith/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-CONTEXT.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create NWConnection Async Wrapper</name>
  <files>
    - Sources/PingMonitor/Services/ConnectionWrapper.swift
  </files>
  <action>
Create ConnectionWrapper.swift that bridges NWConnection's callback-based API to async/await.

Key implementation details (from RESEARCH.md):

1. Use withCheckedThrowingContinuation to wrap NWConnection state changes
2. Use withTaskCancellationHandler to cancel connection when task is cancelled
3. Track continuation resume with a flag to prevent double-resume crashes
4. Create fresh connection per call (not pooled) per user decision

```swift
import Network

struct ConnectionWrapper: Sendable {
    private let queue = DispatchQueue(label: "ConnectionWrapper", qos: .userInitiated)

    /// Measures time to establish TCP/UDP connection
    /// - Parameters:
    ///   - host: Target hostname or IP
    ///   - port: Target port
    ///   - parameters: NWParameters (.tcp or .udp)
    /// - Returns: Duration of connection establishment
    /// - Throws: PingError on failure
    func measureConnection(
        host: String,
        port: UInt16,
        parameters: NWParameters
    ) async throws -> Duration {
        let startTime = ContinuousClock.now

        let endpoint = NWEndpoint.hostPort(
            host: NWEndpoint.Host(host),
            port: NWEndpoint.Port(rawValue: port)!
        )
        let connection = NWConnection(to: endpoint, using: parameters)

        try await withTaskCancellationHandler {
            try await withCheckedThrowingContinuation { (continuation: CheckedContinuation<Void, Error>) in
                // Flag to prevent double resume (NWConnection can fire multiple state updates)
                var didResume = false
                let lock = NSLock()

                connection.stateUpdateHandler = { state in
                    lock.lock()
                    defer { lock.unlock() }
                    guard !didResume else { return }

                    switch state {
                    case .ready:
                        didResume = true
                        // Cancel immediately - we only needed to measure connection time
                        connection.cancel()
                        continuation.resume()

                    case .failed(let error):
                        didResume = true
                        connection.cancel()
                        continuation.resume(throwing: PingError.connectionFailed(error.localizedDescription))

                    case .cancelled:
                        didResume = true
                        continuation.resume(throwing: PingError.cancelled)

                    case .waiting(let error):
                        // Connection is waiting (e.g., no network)
                        // Treat as failure, don't wait indefinitely
                        didResume = true
                        connection.cancel()
                        continuation.resume(throwing: PingError.connectionFailed(error.localizedDescription))

                    default:
                        // .setup, .preparing - wait for final state
                        break
                    }
                }

                connection.start(queue: queue)
            }
        } onCancel: {
            // Immediately cancel connection when task is cancelled
            connection.cancel()
        }

        return ContinuousClock.now - startTime
    }
}
```

Critical patterns:
- NSLock protects didResume flag (callback may fire from any thread)
- .waiting state treated as failure (indicates network issue)
- connection.cancel() called in ALL terminal states
- withTaskCancellationHandler ensures cleanup on external cancellation
  </action>
  <verify>
Run `swift build` - ConnectionWrapper compiles.
Verify imports: Network, Foundation (for NSLock).
Verify PingError is used (import from Models).
  </verify>
  <done>
ConnectionWrapper.swift exists with measureConnection async method. Uses withCheckedThrowingContinuation for callback bridging. Uses withTaskCancellationHandler for cleanup. Double-resume protected with flag and lock.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create PingService Actor</name>
  <files>
    - Sources/PingMonitor/Services/PingService.swift
  </files>
  <action>
Create the PingService actor that orchestrates ping operations with timeout racing.

Key implementation details (from RESEARCH.md):

1. Actor isolation serializes access to shared state
2. Timeout via task racing (not timers) for immediate enforcement
3. ContinuousClock for type-safe latency measurement
4. Fresh ConnectionWrapper per ping (no pooling)

```swift
import Network

actor PingService {
    private let connectionWrapper = ConnectionWrapper()
    private let defaultTimeout: Duration = .seconds(3)  // Per user decision

    /// Ping a host and measure latency
    /// - Parameters:
    ///   - host: Host configuration
    /// - Returns: PingResult with latency or error
    func ping(host: Host) async -> PingResult {
        await ping(
            address: host.address,
            port: host.port,
            protocolType: host.protocolType,
            timeout: host.timeout
        )
    }

    /// Ping by address with explicit parameters
    func ping(
        address: String,
        port: UInt16,
        protocolType: Host.ProtocolType = .tcp,
        timeout: Duration? = nil
    ) async -> PingResult {
        let effectiveTimeout = timeout ?? defaultTimeout
        let parameters: NWParameters = protocolType == .tcp ? .tcp : .udp

        do {
            // Race connection against timeout
            let latency = try await withThrowingTaskGroup(of: Duration.self) { group in
                // Task 1: Actual connection
                group.addTask {
                    try await self.connectionWrapper.measureConnection(
                        host: address,
                        port: port,
                        parameters: parameters
                    )
                }

                // Task 2: Timeout
                group.addTask {
                    try await Task.sleep(for: effectiveTimeout)
                    throw PingError.timeout
                }

                // First to complete wins
                defer { group.cancelAll() }

                guard let result = try await group.next() else {
                    throw PingError.cancelled
                }
                return result
            }

            return .success(host: address, port: port, latency: latency)

        } catch let error as PingError {
            return .failure(host: address, port: port, error: error)
        } catch is CancellationError {
            return .failure(host: address, port: port, error: .cancelled)
        } catch {
            return .failure(host: address, port: port, error: .connectionFailed(error.localizedDescription))
        }
    }

    /// Ping multiple hosts with concurrency limit
    /// - Parameters:
    ///   - hosts: Array of hosts to ping
    ///   - maxConcurrent: Maximum simultaneous pings (default: 10 per user decision)
    /// - Returns: Array of results in same order as input hosts
    func pingAll(hosts: [Host], maxConcurrent: Int = 10) async -> [PingResult] {
        guard !hosts.isEmpty else { return [] }

        // Use actor-isolated dictionary to maintain order
        var results: [UUID: PingResult] = [:]

        await withTaskGroup(of: (UUID, PingResult).self) { group in
            var index = 0

            // Start initial batch
            for _ in 0..<min(maxConcurrent, hosts.count) {
                let host = hosts[index]
                index += 1
                group.addTask {
                    let result = await self.ping(host: host)
                    return (host.id, result)
                }
            }

            // Add new task as each completes (throttling pattern)
            for await (id, result) in group {
                results[id] = result

                if index < hosts.count {
                    let host = hosts[index]
                    index += 1
                    group.addTask {
                        let result = await self.ping(host: host)
                        return (host.id, result)
                    }
                }
            }
        }

        // Return results in original order
        return hosts.compactMap { results[$0.id] }
    }
}
```

Critical patterns:
- withThrowingTaskGroup for timeout racing (first to complete wins)
- defer { group.cancelAll() } ensures loser task is cancelled
- pingAll uses throttling pattern (add new as each completes)
- Results returned in original host order
  </action>
  <verify>
Run `swift build` - PingService compiles.
Verify actor keyword is used (not class).
Verify withThrowingTaskGroup is used (not timers).
Verify ConnectionWrapper is used (not raw NWConnection).
  </verify>
  <done>
PingService actor exists with ping() and pingAll() methods. Uses timeout racing via withThrowingTaskGroup. Respects 3-second default timeout. pingAll throttles to max 10 concurrent. Returns PingResult with Duration latency on success.
  </done>
</task>

</tasks>

<verification>
1. `swift build` compiles without errors
2. ConnectionWrapper uses withCheckedThrowingContinuation (grep confirms)
3. ConnectionWrapper uses withTaskCancellationHandler (grep confirms)
4. PingService is an actor (not class)
5. PingService uses withThrowingTaskGroup for timeout (not timers)
6. Default timeout is 3 seconds (per user decision)
7. pingAll limits to 10 concurrent (per user decision)
</verification>

<success_criteria>
- ConnectionWrapper bridges NWConnection to async/await cleanly
- Double-resume crash prevented with flag protection
- PingService actor provides thread-safe ping operations
- Timeout racing ensures immediate failure at deadline
- Connection cancelled when timeout fires (no late responses)
- pingAll throttles to max 10 concurrent pings
- All code compiles with strict concurrency checking
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-02-SUMMARY.md`
</output>
