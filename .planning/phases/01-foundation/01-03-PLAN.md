---
phase: 01-foundation
plan: 03
type: execute
wave: 3
depends_on: ["01-02"]
files_modified:
  - Sources/PingMonitor/Services/HostHealthTracker.swift
  - Sources/PingMonitor/Services/ConnectionSweeper.swift
  - Sources/PingMonitor/Services/PingScheduler.swift
autonomous: true

must_haves:
  truths:
    - "Host marked down only after 3 consecutive failures (not on first failure)"
    - "Orphaned connections are cleaned up within 30 seconds"
    - "Pings are staggered across the interval (not burst at start)"
    - "Scheduler cancels and restarts when host list changes"
  artifacts:
    - path: "Sources/PingMonitor/Services/HostHealthTracker.swift"
      provides: "Consecutive failure tracking"
      contains: "actor HostHealthTracker"
    - path: "Sources/PingMonitor/Services/ConnectionSweeper.swift"
      provides: "Orphan connection cleanup"
      contains: "actor ConnectionSweeper"
    - path: "Sources/PingMonitor/Services/PingScheduler.swift"
      provides: "Staggered ping orchestration"
      contains: "actor PingScheduler"
  key_links:
    - from: "PingScheduler.swift"
      to: "PingService.swift"
      via: "ping invocation"
      pattern: "pingService\\.ping"
    - from: "PingScheduler.swift"
      to: "HostHealthTracker.swift"
      via: "result recording"
      pattern: "healthTracker\\.record"
    - from: "ConnectionSweeper.swift"
      to: "NWConnection"
      via: "orphan cancellation"
      pattern: "connection\\.cancel"
---

<objective>
Implement supporting services for health tracking, connection cleanup, and ping scheduling.

Purpose: Complete the foundation layer with the orchestration components. HostHealthTracker implements the 3-consecutive-failure rule. ConnectionSweeper provides the safety net for orphaned connections. PingScheduler implements staggered pings across the interval.

Output: Three actor services that complete the ping monitoring foundation.
</objective>

<execution_context>
@/Users/keith/.claude/get-shit-done/workflows/execute-plan.md
@/Users/keith/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-CONTEXT.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create HostHealthTracker Actor</name>
  <files>
    - Sources/PingMonitor/Services/HostHealthTracker.swift
  </files>
  <action>
Create HostHealthTracker that implements the 3-consecutive-failure rule from user decisions.

Key requirements (from CONTEXT.md):
- 3 consecutive failures required before marking host as down
- Success resets failure count to 0
- Reduces false positives from transient failures

```swift
/// Tracks consecutive ping failures to determine host health status.
/// Per user decision: 3 consecutive failures = host down.
actor HostHealthTracker {
    private var consecutiveFailures: [String: Int] = [:]
    private let failureThreshold: Int

    init(failureThreshold: Int = 3) {
        self.failureThreshold = failureThreshold
    }

    /// Records a ping result and returns whether host should be considered up.
    /// - Parameters:
    ///   - host: Host identifier (address)
    ///   - success: Whether the ping succeeded
    /// - Returns: true if host is considered up, false if down
    func recordResult(host: String, success: Bool) -> Bool {
        if success {
            consecutiveFailures[host] = 0
            return true  // Host is up
        } else {
            let failures = (consecutiveFailures[host] ?? 0) + 1
            consecutiveFailures[host] = failures
            return failures < failureThreshold  // Still up until threshold
        }
    }

    /// Records a PingResult directly
    func recordResult(_ result: PingResult) -> Bool {
        recordResult(host: result.host, success: result.isSuccess)
    }

    /// Check if host is currently marked as down
    func isHostDown(_ host: String) -> Bool {
        (consecutiveFailures[host] ?? 0) >= failureThreshold
    }

    /// Get current failure count for a host
    func failureCount(for host: String) -> Int {
        consecutiveFailures[host] ?? 0
    }

    /// Reset failure count for a host (e.g., when manually refreshed)
    func reset(host: String) {
        consecutiveFailures[host] = 0
    }

    /// Reset all failure counts
    func resetAll() {
        consecutiveFailures.removeAll()
    }
}
```

Key patterns:
- Actor isolation ensures thread-safe failure counting
- Threshold configurable but defaults to 3 per user decision
- Convenience method accepts PingResult directly
  </action>
  <verify>
Run `swift build` - HostHealthTracker compiles.
Verify actor keyword is used.
Verify failureThreshold defaults to 3.
  </verify>
  <done>
HostHealthTracker actor exists. Tracks consecutive failures per host. Returns false (host down) only after 3 consecutive failures. Success resets count. Provides isHostDown() and reset() methods.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create ConnectionSweeper Actor</name>
  <files>
    - Sources/PingMonitor/Services/ConnectionSweeper.swift
  </files>
  <action>
Create ConnectionSweeper that periodically cleans up orphaned connections.

Key requirements (from CONTEXT.md and RESEARCH.md):
- Periodic sweep to catch orphaned connections
- 10-second sweep interval (from research recommendation)
- 30-second max age before connection considered orphaned
- Cancel all connections when app suspended/backgrounded

```swift
import Network

/// Tracks active connections and sweeps orphaned ones.
/// Safety net for connections that weren't properly cleaned up.
actor ConnectionSweeper {
    struct TrackedConnection: Sendable {
        let connection: NWConnection
        let startTime: ContinuousClock.Instant
    }

    private var activeConnections: [UUID: TrackedConnection] = [:]
    private var sweepTask: Task<Void, Never>?

    private let sweepInterval: Duration
    private let maxAge: Duration

    init(sweepInterval: Duration = .seconds(10), maxAge: Duration = .seconds(30)) {
        self.sweepInterval = sweepInterval
        self.maxAge = maxAge
    }

    /// Register a connection for tracking. Call when connection is created.
    /// - Returns: UUID to use when unregistering
    func register(_ connection: NWConnection) -> UUID {
        let id = UUID()
        activeConnections[id] = TrackedConnection(
            connection: connection,
            startTime: .now
        )
        return id
    }

    /// Unregister a connection. Call when connection completes or is cancelled.
    func unregister(_ id: UUID) {
        activeConnections.removeValue(forKey: id)
    }

    /// Start the periodic sweep task
    func startSweeping() {
        guard sweepTask == nil else { return }

        sweepTask = Task {
            while !Task.isCancelled {
                try? await Task.sleep(for: sweepInterval)
                await sweep()
            }
        }
    }

    /// Stop the periodic sweep task
    func stopSweeping() {
        sweepTask?.cancel()
        sweepTask = nil
    }

    /// Perform one sweep, cancelling connections older than maxAge
    func sweep() {
        let now = ContinuousClock.now
        var orphaned: [UUID] = []

        for (id, tracked) in activeConnections {
            if now - tracked.startTime > maxAge {
                tracked.connection.cancel()
                orphaned.append(id)
            }
        }

        for id in orphaned {
            activeConnections.removeValue(forKey: id)
        }
    }

    /// Cancel all active connections immediately.
    /// Call when app is suspended/backgrounded.
    func cancelAll() {
        for (_, tracked) in activeConnections {
            tracked.connection.cancel()
        }
        activeConnections.removeAll()
    }

    /// Get count of currently tracked connections (for debugging/testing)
    var activeCount: Int {
        activeConnections.count
    }
}
```

Key patterns:
- Actor isolation for thread-safe connection tracking
- Periodic task for sweeping (10-second interval)
- 30-second max age identifies orphans
- cancelAll() for app suspension
  </action>
  <verify>
Run `swift build` - ConnectionSweeper compiles.
Verify actor keyword is used.
Verify sweep interval defaults to 10 seconds.
Verify max age defaults to 30 seconds.
  </verify>
  <done>
ConnectionSweeper actor exists. register() and unregister() track connections. startSweeping() runs periodic cleanup every 10 seconds. sweep() cancels connections older than 30 seconds. cancelAll() for immediate cleanup on suspend.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create PingScheduler Actor</name>
  <files>
    - Sources/PingMonitor/Services/PingScheduler.swift
  </files>
  <action>
Create PingScheduler that orchestrates staggered pings across the interval.

Key requirements (from CONTEXT.md):
- Stagger pings evenly across interval (not burst at start)
- Cancel and restart when host list changes
- Cancel and restart when user triggers manual refresh
- Use PingService for actual pings
- Use HostHealthTracker for result recording

```swift
/// Orchestrates periodic ping cycles with staggered timing.
actor PingScheduler {
    private let pingService: PingService
    private let healthTracker: HostHealthTracker

    private var pingTask: Task<Void, Never>?
    private var currentHosts: [Host] = []
    private var interval: Duration = .seconds(30)

    /// Callback for ping results (for UI updates)
    typealias ResultHandler = @Sendable (PingResult, Bool) -> Void  // result, isHostUp
    private var onResult: ResultHandler?

    init(pingService: PingService, healthTracker: HostHealthTracker) {
        self.pingService = pingService
        self.healthTracker = healthTracker
    }

    /// Set callback for ping results
    func setResultHandler(_ handler: @escaping ResultHandler) {
        self.onResult = handler
    }

    /// Start periodic ping cycle with given hosts and interval
    func start(hosts: [Host], interval: Duration = .seconds(30)) {
        self.interval = interval
        self.currentHosts = hosts

        // Cancel existing task and start fresh
        pingTask?.cancel()

        guard !hosts.isEmpty else { return }

        pingTask = Task {
            while !Task.isCancelled {
                await pingCycleWithStagger()
                try? await Task.sleep(for: interval)
            }
        }
    }

    /// Stop the ping cycle
    func stop() {
        pingTask?.cancel()
        pingTask = nil
    }

    /// Update hosts - cancels current cycle and restarts
    func updateHosts(_ hosts: [Host]) {
        start(hosts: hosts, interval: interval)
    }

    /// Trigger manual refresh - cancels current cycle and restarts immediately
    func refresh() {
        start(hosts: currentHosts, interval: interval)
    }

    /// Perform a single ping cycle with staggered timing
    private func pingCycleWithStagger() async {
        let hosts = currentHosts
        guard !hosts.isEmpty else { return }

        // Distribute pings evenly across 80% of interval (leave 20% buffer)
        let effectiveInterval = interval * 0.8
        let staggerDelay = effectiveInterval / hosts.count

        await withTaskGroup(of: Void.self) { group in
            for (index, host) in hosts.enumerated() {
                group.addTask {
                    // Stagger start times
                    if index > 0 {
                        try? await Task.sleep(for: staggerDelay * index)
                    }

                    guard !Task.isCancelled else { return }

                    let result = await self.pingService.ping(host: host)
                    let isUp = await self.healthTracker.recordResult(result)

                    // Notify callback (if set)
                    await MainActor.run {
                        self.onResult?(result, isUp)
                    }
                }
            }
        }
    }

    /// Check if scheduler is currently running
    var isRunning: Bool {
        pingTask != nil && !pingTask!.isCancelled
    }
}
```

Key patterns:
- Stagger formula: effectiveInterval / hostCount
- Uses 80% of interval for pings, 20% buffer
- Cancel and restart on host changes or manual refresh
- Result handler for UI updates (called on MainActor)
- TaskGroup for concurrent staggered pings
  </action>
  <verify>
Run `swift build` - PingScheduler compiles.
Verify actor keyword is used.
Verify stagger calculation divides interval by host count.
Verify cancel happens before restart in updateHosts and refresh.
  </verify>
  <done>
PingScheduler actor exists. start() begins periodic cycle with staggered pings. updateHosts() cancels and restarts with new hosts. refresh() triggers immediate restart. Uses PingService for pings and HostHealthTracker for result recording. Stagger spreads pings across 80% of interval.
  </done>
</task>

</tasks>

<verification>
1. `swift build` compiles without errors
2. All three files use actor keyword (grep confirms)
3. HostHealthTracker threshold is 3 (grep confirms)
4. ConnectionSweeper sweep interval is 10 seconds (grep confirms)
5. ConnectionSweeper max age is 30 seconds (grep confirms)
6. PingScheduler stagger calculation uses interval / hostCount pattern
</verification>

<success_criteria>
- HostHealthTracker marks host down only after 3 consecutive failures
- ConnectionSweeper cleans orphaned connections (30+ seconds old)
- ConnectionSweeper.cancelAll() for app suspension
- PingScheduler staggers pings evenly across interval
- PingScheduler cancels and restarts on host list changes
- All services are actors with proper isolation
- All code compiles with strict concurrency checking
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-03-SUMMARY.md`
</output>
